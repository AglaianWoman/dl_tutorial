{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original model\n",
    "\n",
    "We start with the original model. There seems to be a competition how to define a network with the least possible amount of code. The slim library includes a **arg_scope** which allows define defaults for aguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.variable_scope('vgg_16', [inputs]) as sc:\n",
    "    with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    "                          activation_fn=tf.nn.relu,\n",
    "                          weights_initializer=tf.truncated_normal_initializer(0.0, 0.01),\n",
    "                          weights_regularizer=slim.l2_regularizer(0.0005)):\n",
    "        images = tf.placeholder(tf.float32, [None, None, None, 3], name='images')\n",
    "        inputs = tf.image.resize_images(images, (224,224))\n",
    "        net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "        net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "        net = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
    "        net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
    "        net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
    "        net = slim.conv2d(net, 4096, [7, 7], padding='VALID', scope='fc6')\n",
    "        net = slim.conv2d(net, 4096, [1, 1], scope='fc7')\n",
    "        net = slim.conv2d(net, 1000, [1, 1], activation_fn=None, normalizer_fn=None,scope='fc8')\n",
    "\n",
    "tf.train.SummaryWriter('/tmp/dumm/fine_tuning', tf.get_default_graph()).close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "variables_to_restore = slim.get_variables_to_restore()\n",
    "init_assign_op, init_feed_dict = \\\n",
    "    slim.assign_from_checkpoint('/Users/oli/Dropbox/server_sync/tf_slim_models/vgg_16.ckpt', variables_to_restore)\n",
    "sess = tf.Session()\n",
    "sess.run(init_assign_op, init_feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267 standard poodle 18.2776\n",
      "265 toy poodle 12.6826\n",
      "266 miniature poodle 12.4879\n",
      "160 Afghan hound, Afghan 10.2724\n",
      "221 Irish water spaniel 10.2163\n",
      "355 llama 10.0407\n",
      "244 Tibetan mastiff 9.9589\n",
      "368 gibbon, Hylobates lar 9.12196\n",
      "903 wig 9.04713\n",
      "260 chow, chow chow 8.27523\n"
     ]
    }
   ],
   "source": [
    "from imagenet_classes import class_names\n",
    "img1 = imread('poodle.jpg')\n",
    "feed_vals = [img1]\n",
    "np.shape(feed_vals)\n",
    "prob = sess.run(net, feed_dict={images:feed_vals})[0,0,0,]\n",
    "preds = (np.argsort(prob)[::-1])[0:10]\n",
    "for p in preds:\n",
    "    print p, class_names[p], prob[p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.variable_scope('vgg_16', [inputs]) as sc:\n",
    "    with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    "                          activation_fn=tf.nn.relu,\n",
    "                          weights_initializer=tf.truncated_normal_initializer(0.0, 0.01),\n",
    "                          weights_regularizer=slim.l2_regularizer(0.0005)):\n",
    "        images = tf.placeholder(tf.float32, [None, None, None, 3], name='images')\n",
    "        inputs = tf.image.resize_images(images, (224,224))\n",
    "        net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "        net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "        net = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
    "        net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
    "        net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
    "        shape = int(np.prod(net.get_shape()[1:]))\n",
    "        net = tf.reshape(net, [-1, shape])\n",
    "        net = slim.fully_connected(net, 1000, scope='fc6') #Only 1000 \n",
    "        net = slim.dropout(net, 0.5, scope='dropout6')\n",
    "        net = slim.fully_connected(net, 10, scope='fc7', activation_fn=None, normalizer_fn=None) #Only 10\n",
    "        # This would be the original vgg16. We replace these layers with FC layers and less classes\n",
    "        #net = slim.conv2d(net, 4096, [7, 7], padding='VALID', scope='fc6')\n",
    "        #net = slim.conv2d(net, 4096, [1, 1], scope='fc7')\n",
    "        #net = slim.conv2d(net, 1000, [1, 1], activation_fn=None, normalizer_fn=None,scope='fc8')\n",
    "       \n",
    "tf.train.SummaryWriter('/tmp/dumm/fine_tuned', tf.get_default_graph()).close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.ops.variables.Variable at 0x10e7c8850>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x10e7c86d0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x10e7c8b10>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x10e7c8410>]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note we call the network studid, so that we don't get a hold for the tensors we need.\n",
    "vars_to_restore = slim.get_variables(scope='vgg_16/conv1')\n",
    "#vars_to_restore.append(slim.get_variables(scope='vgg_16/conv2'))\n",
    "vars_to_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vars_to_restore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored.\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "restorer = tf.train.Saver(vars_to_restore)\n",
    "restorer.restore(sess, '/Users/oli/Dropbox/server_sync/tf_slim_models/vgg_16.ckpt')\n",
    "print(\"Model restored.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.26071405e-04,   4.15087328e-04,  -9.35655044e-05,\n",
       "          7.45166559e-04,  -3.84996965e-04,  -1.29617998e-04,\n",
       "         -3.65308631e-04,   2.90129654e-04,  -1.10490248e-04,\n",
       "          7.67014455e-04]], dtype=float32)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(net, feed_dict={images:feed_vals})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
