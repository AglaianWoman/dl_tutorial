{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Embedding for the visualizer\n",
    "\n",
    "This notebook shows how to create embeddings for the PCA / tSNE visualizer in tensorboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.12.0-rc1'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import scipy\n",
    "import cPickle\n",
    "%matplotlib inline\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets as nets\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of the data\n",
    "The images can be obtained from: http://www.cs.toronto.edu/~kriz/cifar.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = cPickle.load(fo)\n",
    "    fo.close()\n",
    "    data = dict['data']\n",
    "    imgs = np.transpose(np.reshape(data,(-1,32,32,3), order='F'),axes=(0,2,1,3)) #order batch,x,y,color\n",
    "    y = np.asarray(dict['labels'], dtype='uint8')\n",
    "    return y, imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000, 32, 32, 3))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, imgs = unpickle('/Users/oli/Dropbox/data/CIFAR-10/cifar-10-batches-py/test_batch')\n",
    "y.shape, imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the models\n",
    "We use a training VGG16 network. The weights for the model can be downloaded as described in http://randomthoughtsonr.blogspot.de/2016/11/image-classification-in-r-using-trained.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables to restore 32\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "images = tf.placeholder(tf.float32, [None, None, None, 3])\n",
    "imgs_scaled = tf.image.resize_images(images, (224,224))\n",
    "slim.nets.vgg.vgg_16(imgs_scaled, is_training=False)\n",
    "variables_to_restore = slim.get_variables_to_restore()\n",
    "print('Number of variables to restore {}'.format(len(variables_to_restore)))\n",
    "init_assign_op, init_feed_dict = slim.assign_from_checkpoint('/Users/oli/Dropbox/server_sync/tf_slim_models/vgg_16.ckpt', variables_to_restore)\n",
    "sess = tf.Session()\n",
    "sess.run(init_assign_op, init_feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 32, 32, 3), (3, 1, 1, 4096))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = tf.get_default_graph()\n",
    "feed = g.get_tensor_by_name('Placeholder:0')\n",
    "fetch = g.get_tensor_by_name('vgg_16/fc6/BiasAdd:0')\n",
    "\n",
    "# Feeding 3 images through the net just for testing\n",
    "feed_vals = imgs[0:3]\n",
    "res = sess.run(fetch, feed_dict={feed:feed_vals})\n",
    "np.shape(feed_vals), res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the embedding\n",
    "We now create a matrix with the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = imgs.shape[0]\n",
    "N = 3 #For testing\n",
    "p = res.shape[3]\n",
    "\n",
    "EMB = np.zeros((N, p), dtype='float32')\n",
    "for i in range(N): #Of course you could do mini-batches\n",
    "    EMB[i] = sess.run(fetch, feed_dict={feed: imgs[i:i+1,:]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing out the embedding matrix\n",
    "We now write out the embedding matrix in the proper format. The "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/dumm/model2.ckpt-1'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The embedding variable, which needs to be stored\n",
    "# Note this must a Variable not a Tensor!\n",
    "LOG_DIR = '/tmp/dumm'\n",
    "\n",
    "embedding_var = tf.Variable(EMB,  name='Embedding_of_fc6')\n",
    "sess.run(embedding_var.initializer)\n",
    "summary_writer = tf.summary.FileWriter(LOG_DIR)\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = embedding_var.name\n",
    "\n",
    "# Comment out if you don't have metadata\n",
    "embedding.metadata_path = os.path.join(LOG_DIR, 'metadata.tsv')\n",
    "\n",
    "# Comment out if you don't want sprites\n",
    "embedding.sprite.image_path = os.path.join(LOG_DIR, 'sprite.png')\n",
    "embedding.sprite.single_image_dim.extend([imgs.shape[1], imgs.shape[1]])\n",
    "\n",
    "projector.visualize_embeddings(summary_writer, config)\n",
    "saver = tf.train.Saver([embedding_var])\n",
    "saver.save(sess, os.path.join(LOG_DIR, 'model2.ckpt'), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the meta data (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = ['plane','auto','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "metadata_file = open(os.path.join(LOG_DIR, 'metadata.tsv'), 'w')\n",
    "metadata_file.write('Name\\tClass\\n')\n",
    "for i in range(N):\n",
    "    metadata_file.write('%06d\\t%s\\n' % (i, names[y[i]]))\n",
    "metadata_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Taken from: https://github.com/tensorflow/tensorflow/issues/6322\n",
    "def images_to_sprite(data):\n",
    "    \"\"\"Creates the sprite image along with any necessary padding\n",
    "\n",
    "    Args:\n",
    "      data: NxHxW[x3] tensor containing the images.\n",
    "\n",
    "    Returns:\n",
    "      data: Properly shaped HxWx3 image with any necessary padding.\n",
    "    \"\"\"\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.tile(data[...,np.newaxis], (1,1,1,3))\n",
    "    data = data.astype(np.float32)\n",
    "    min = np.min(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1,2,3,0) - min).transpose(3,0,1,2)\n",
    "    max = np.max(data.reshape((data.shape[0], -1)), axis=1)\n",
    "    data = (data.transpose(1,2,3,0) / max).transpose(3,0,1,2)\n",
    "    # Inverting the colors seems to look better for MNIST\n",
    "    #data = 1 - data\n",
    "\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "    padding = ((0, n ** 2 - data.shape[0]), (0, 0),\n",
    "            (0, 0)) + ((0, 0),) * (data.ndim - 3)\n",
    "    data = np.pad(data, padding, mode='constant',\n",
    "            constant_values=0)\n",
    "    # Tile the individual thumbnails into an image.\n",
    "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3)\n",
    "            + tuple(range(4, data.ndim + 1)))\n",
    "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sprite = images_to_sprite(imgs[0:3])\n",
    "scipy.misc.imsave(os.path.join(LOG_DIR, 'sprite.png'), sprite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
